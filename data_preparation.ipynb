{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "163185bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from datetime import date, datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bb4f458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAY MAU.csv\n",
      "Index(['datetime', 'flow_in', 'flow_out1', 'flow_out2', 'flow_out3', 'temp',\n",
      "       'ph', 'tss', 'do', 'cod', 'bod', 'toc', 'no3', 'nh4', 'po4', 'total_n',\n",
      "       'total_p'],\n",
      "      dtype='object')\n",
      "TU SON.csv\n",
      "Index(['datetime', 'flow_in', 'flow_out1', 'flow_out2', 'flow_out3', 'temp',\n",
      "       'ph', 'tss', 'do', 'cod', 'bod', 'toc', 'no3', 'nh4', 'po4', 'total_n',\n",
      "       'total_p'],\n",
      "      dtype='object')\n",
      "CAU NGA.csv\n",
      "Index(['datetime', 'flow_in', 'flow_out1', 'flow_out2', 'flow_out3', 'temp',\n",
      "       'ph', 'tss', 'do', 'cod', 'bod', 'toc', 'no3', 'nh4', 'po4', 'total_n',\n",
      "       'total_p'],\n",
      "      dtype='object')\n",
      "BTLVT.csv\n",
      "Index(['datetime', 'flow_in', 'flow_out1', 'flow_out2', 'flow_out3', 'temp',\n",
      "       'ph', 'tss', 'do', 'cod', 'bod', 'toc', 'no3', 'nh4', 'po4', 'total_n',\n",
      "       'total_p'],\n",
      "      dtype='object')\n",
      "YENSO.csv\n",
      "Index(['datetime', 'flow_in', 'flow_out1', 'flow_out2', 'flow_out3', 'temp',\n",
      "       'ph', 'tss', 'do', 'cod', 'bod', 'toc', 'no3', 'nh4', 'po4', 'total_n',\n",
      "       'total_p'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_all = []\n",
    "file_lst_used = []\n",
    "file_lst = os.listdir('NMXLNT')\n",
    "for file_name in file_lst:\n",
    "    if \"VINH NIEM\" not in file_name and \"HO TAY\" not in file_name:\n",
    "        df = pd.read_csv(f\"NMXLNT/{file_name}\")\n",
    "        df = df.drop_duplicates().reset_index().drop(\"index\", axis = 1) # after some inspection, realize there's some duplicates\n",
    "        df_all.append(df)\n",
    "        file_lst_used.append(file_name)\n",
    "        print(file_name)\n",
    "        print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f54fc7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_fraction_used = [i/2 for i in range(2)]\n",
    "lag_used = [i + t for t in time_fraction_used for i in range(4, 12)] + [12]\n",
    "actual_lag_used = [round(i + t, 2) for t in time_fraction_used for i in range(4, 12)] + [12]\n",
    "features_used = [f\"cod_prev_{i}\" for i in actual_lag_used] + \\\n",
    "                [f\"temp_prev_{i}\" for i in actual_lag_used] + \\\n",
    "                [f\"ph_prev_{i}\" for i in actual_lag_used] + \\\n",
    "                [f\"tss_prev_{i}\" for i in actual_lag_used] + \\\n",
    "                [f\"flow_out_prev_{i}\" for i in actual_lag_used] + \\\n",
    "                [f\"nh4_prev_{i}\" for i in actual_lag_used] + \\\n",
    "                [\"sin_hour\", \"sin_day\", \"sin_month\", \"cod\"] + \\\n",
    "                [\"datetime\", \"Location\"]\n",
    "\n",
    "# try to plot cod and find error data in this\n",
    "def find_prev_mean(row, df_copy, num_minutes):\n",
    "    # find the mean of last num_minutes minutes\n",
    "    begin_time, end_time = row[\"datetime\"] - pd.Timedelta(minutes = num_minutes), row[\"datetime\"]\n",
    "    past_mean = df_copy[(df_copy[\"datetime\"] >= begin_time) & (df_copy[\"datetime\"] < end_time)][\"cod\"].mean()\n",
    "    if pd.isna(past_mean) or past_mean == 0:\n",
    "        return True\n",
    "    return abs(row[\"cod\"] / past_mean - 1) > 0.2\n",
    "\n",
    "def preprocessing(df, file_name):\n",
    "    df[\"Location\"] = file_name\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "    df[\"minute\"] = df[\"datetime\"].dt.minute\n",
    "    df[\"sin_minute\"] = np.sin(df[\"minute\"] / 60 * 2 * np.pi)\n",
    "    df[\"hour\"] = (df[\"datetime\"].dt.hour)\n",
    "    df[\"sin_hour\"] = np.sin(df[\"hour\"] / 24 * 2 * np.pi)\n",
    "    #df[\"dayofweek\"] = (df[\"datetime\"].dt.dayofweek)\n",
    "    df[\"day\"] = (df[\"datetime\"].dt.day)\n",
    "    df[\"sin_day\"] = np.sin(df[\"day\"] / 31 * 2 * np.pi)\n",
    "    df[\"month\"] = (df[\"datetime\"].dt.month)\n",
    "    df[\"sin_month\"] = np.sin(df[\"month\"] / 12 * 2 * np.pi)\n",
    "    df = df[~df[\"cod\"].isna()].reset_index().drop(\"index\", axis = 1)\n",
    "    df = df[df[\"cod\"] > 0].reset_index().drop(\"index\", axis = 1) # assumption of cod > 0\n",
    "    if \"flow_in\" not in df.columns:\n",
    "        df[\"flow_in\"] = df[\"flow_in1\"] + df[\"flow_in2\"]\n",
    "    df[\"flow_out\"] = df[\"flow_out1\"].fillna(0) + df[\"flow_out2\"].fillna(0) + df[\"flow_out3\"].fillna(0)\n",
    "    #print(df[\"cod\"].isna().sum())\n",
    "    df = df.reset_index().drop(\"index\", axis = 1)\n",
    "    temp_df = deepcopy(df)\n",
    "    last_row_with_time_within = {\n",
    "        j: [] for j in lag_used # store between 4 - 8 hours since we are trying to predict the next 4-8 hours\n",
    "    }\n",
    "    curr_row = {\n",
    "        j: 0 for j in lag_used\n",
    "    }\n",
    "    for i in tqdm(range(df.shape[0])):\n",
    "        for j in lag_used:\n",
    "            # we first try to find until we find first instance that is STRICTLY LESS THAN k hours before current time\n",
    "            # then the previous instance is the instance that might before around 4 hours before current time\n",
    "            while curr_row[j] < i and (df.loc[i, \"datetime\"] - df.loc[curr_row[j], \"datetime\"]) / pd.Timedelta(minutes=1) >= 60 * j:\n",
    "                curr_row[j] += 1\n",
    "            # when we stop is when we do not see a fit row, try to check if that fit row actually fit \n",
    "            # a fit would be from k - < k+1 hours before (curr_row - 1 would be our answer)\n",
    "            if curr_row[j] <= i and curr_row[j] >= 1 and \\\n",
    "               (df.loc[i, \"datetime\"] - df.loc[curr_row[j] - 1, \"datetime\"]) / pd.Timedelta(minutes=1) >= 60 * j and \\\n",
    "               (df.loc[i, \"datetime\"] - df.loc[curr_row[j] - 1, \"datetime\"]) / pd.Timedelta(minutes=1) < 60 * (j+1):\n",
    "                last_row_with_time_within[j].append(curr_row[j] - 1)\n",
    "            else:\n",
    "                # we stop because we have no answer\n",
    "                last_row_with_time_within[j].append(None)\n",
    "    for j in lag_used:\n",
    "        df[f\"last_row_with_time_within_{round(j, 2)}hour\"] = last_row_with_time_within[j]\n",
    "    # need to separete these two steps since after we inner join, we will lose some rows\n",
    "    for j in lag_used:\n",
    "        df2 = deepcopy(temp_df.reset_index())\n",
    "        df = df.merge(df2, how = \"inner\", left_on = f\"last_row_with_time_within_{round(j, 2)}hour\", right_on = \"index\", suffixes=(\"\", f\"_prev_{round(j, 2)}\"))\n",
    "        #print(np.mean(((df[\"datetime\"] - df[f\"datetime_prev_{j}\"]) / pd.Timedelta(minutes=1)) >= 60*j))\n",
    "    # print(df.shape[0])\n",
    "    # df[\"zscore\"] = (df[\"cod\"] - df[\"cod\"].rolling(50).mean()) / df[\"cod\"].rolling(50).std()\n",
    "    # df = df[df[\"zscore\"].abs() <= 6.5].reset_index().drop(\"index\", axis = 1)\n",
    "    # print(df.shape[0])\n",
    "    temp = deepcopy(df)\n",
    "    df[\"abnormal\"] = df.apply(lambda x: find_prev_mean(x, temp, 30), axis = 1)\n",
    "    df = df[~df[\"abnormal\"]].reset_index().drop(\"index\", axis = 1)\n",
    "    df = df[features_used]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eac026d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89863/89863 [01:07<00:00, 1334.78it/s]\n",
      "100%|██████████| 78446/78446 [01:01<00:00, 1283.55it/s]\n",
      "100%|██████████| 76194/76194 [00:58<00:00, 1301.33it/s]\n",
      "100%|██████████| 79637/79637 [01:01<00:00, 1291.15it/s]\n",
      "100%|██████████| 73175/73175 [00:55<00:00, 1308.80it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(df_all)):\n",
    "    df_all[i] = preprocessing(df_all[i], file_lst_used[i])\n",
    "df_all = pd.concat(df_all, ignore_index = True)\n",
    "df_all.to_csv(\"NMXLNT_df.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
