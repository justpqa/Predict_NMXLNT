{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190b9c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from datetime import date, datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import optuna\n",
    "from optuna.samplers import RandomSampler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import multiprocessing\n",
    "max_n_jobs = multiprocessing.cpu_count()\n",
    "print(f\"Maximum n_jobs you can use: {max_n_jobs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fe051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"NMXLNT_df.csv\")\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "print(df[\"Location\"].unique())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3c1123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to plot cod against time in all data\n",
    "fig, ax = plt.subplots(nrows = 3, ncols = 2, figsize = (10, 15))\n",
    "for inx, loc in enumerate(df[\"Location\"].unique()):\n",
    "    x, y = inx // 2, inx % 2\n",
    "    sns.scatterplot(df[df[\"Location\"] == loc], x = \"datetime\", y = \"cod\", ax = ax[x][y])\n",
    "    ax[x][y].set_title(loc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908e2d67",
   "metadata": {},
   "source": [
    "Make CV split & compare with baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5080c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cv_split(df, features_used, cv = 5):\n",
    "    X_train_arr = []\n",
    "    X_test_arr = []\n",
    "    Y_train_arr = []\n",
    "    Y_test_arr = []\n",
    "    start_month = 13 - cv\n",
    "    for i in range(cv):\n",
    "        train = deepcopy(df[df[\"datetime\"].dt.month < start_month + i].reset_index().drop(\"index\", axis = 1))\n",
    "        test = deepcopy(df[(df[\"datetime\"].dt.month >= start_month + i) & (df[\"datetime\"].dt.month < start_month + 1 + i)].reset_index().drop(\"index\", axis = 1))\n",
    "        #print(train.shape[0] / (train.shape[0] + test.shape[0]))\n",
    "        X_train_arr.append(train[features_used])\n",
    "        X_test_arr.append(test[features_used])\n",
    "        Y_train_arr.append(train[\"cod\"])\n",
    "        Y_test_arr.append(test[\"cod\"])\n",
    "    return X_train_arr, X_test_arr, Y_train_arr, Y_test_arr\n",
    "\n",
    "def create_cv_split_with_val(df, features_used, cv = 5):\n",
    "    X_train_arr = []\n",
    "    X_val_arr = []\n",
    "    X_test_arr = []\n",
    "    Y_train_arr = []\n",
    "    Y_val_arr = []\n",
    "    Y_test_arr = []\n",
    "    start_month = 13 - cv\n",
    "    for i in range(cv):\n",
    "        train = deepcopy(df[df[\"datetime\"].dt.month < start_month + i - 1].reset_index().drop(\"index\", axis = 1))\n",
    "        val = deepcopy(df[df[\"datetime\"].dt.month == start_month + i - 1].reset_index().drop(\"index\", axis = 1))\n",
    "        test = deepcopy(df[(df[\"datetime\"].dt.month >= start_month + i) & (df[\"datetime\"].dt.month < start_month + 1 + i)].reset_index().drop(\"index\", axis = 1))\n",
    "        #print(train.shape[0] / (train.shape[0] + test.shape[0]))\n",
    "        X_train_arr.append(train[features_used])\n",
    "        X_val_arr.append(val[features_used])\n",
    "        X_test_arr.append(test[features_used])\n",
    "        Y_train_arr.append(train[\"cod\"])\n",
    "        Y_val_arr.append(val[\"cod\"])\n",
    "        Y_test_arr.append(test[\"cod\"])\n",
    "    return X_train_arr, X_val_arr, X_test_arr, Y_train_arr, Y_val_arr, Y_test_arr\n",
    "\n",
    "def create_cv_split_location(df, features_used, loc, cv = 5):\n",
    "    df = df[df[\"Location\"] == loc].reset_index().drop(\"index\", axis = 1)\n",
    "    X_train_arr = []\n",
    "    X_test_arr = []\n",
    "    Y_train_arr = []\n",
    "    Y_test_arr = []\n",
    "    start_month = 13 - cv\n",
    "    for i in range(cv):\n",
    "        train = deepcopy(df[df[\"datetime\"].dt.month < start_month + i].reset_index().drop(\"index\", axis = 1))\n",
    "        test = deepcopy(df[(df[\"datetime\"].dt.month >= start_month + i) & (df[\"datetime\"].dt.month < start_month + 1 + i)].reset_index().drop(\"index\", axis = 1))\n",
    "        #print(train.shape[0] / test.shape[0])\n",
    "        X_train_arr.append(train[features_used])\n",
    "        X_test_arr.append(test[features_used])\n",
    "        Y_train_arr.append(train[\"cod\"])\n",
    "        Y_test_arr.append(test[\"cod\"])\n",
    "    return X_train_arr, X_test_arr, Y_train_arr, Y_test_arr\n",
    "\n",
    "def create_cv_split_diff(df, features_used, time_diff = 4, cv = 5):\n",
    "    X_train_arr = []\n",
    "    X_test_arr = []\n",
    "    Y_train_arr = []\n",
    "    Y_test_arr = []\n",
    "    start_month = 13 - cv\n",
    "    for i in range(cv):\n",
    "        train = deepcopy(df[df[\"datetime\"].dt.month < start_month + i].reset_index().drop(\"index\", axis = 1))\n",
    "        test = deepcopy(df[(df[\"datetime\"].dt.month >= start_month + i) & (df[\"datetime\"].dt.month < start_month + 1 + i)].reset_index().drop(\"index\", axis = 1))\n",
    "        #print(train.shape[0] / test.shape[0])\n",
    "        X_train_arr.append(train[features_used])\n",
    "        X_test_arr.append(test[features_used])\n",
    "        Y_train_arr.append(train[f\"cod_diff_{time_diff}\"])\n",
    "        Y_test_arr.append(test[f\"cod_diff_{time_diff}\"])\n",
    "    return X_train_arr, X_test_arr, Y_train_arr, Y_test_arr\n",
    "\n",
    "def create_cv_split_with_info(df, features_used, cv = 5):\n",
    "    X_train_arr = []\n",
    "    X_test_arr = []\n",
    "    Y_train_arr = []\n",
    "    Y_test_arr = []\n",
    "    info_train_arr = []\n",
    "    info_test_arr = []\n",
    "    start_month = 13 - cv\n",
    "    for i in range(cv):\n",
    "        train = deepcopy(df[df[\"datetime\"].dt.month < start_month + i].reset_index().drop(\"index\", axis = 1))\n",
    "        test = deepcopy(df[(df[\"datetime\"].dt.month >= start_month + i) & (df[\"datetime\"].dt.month < start_month + 1 + i)].reset_index().drop(\"index\", axis = 1))\n",
    "        #print(train.shape[0] / test.shape[0])\n",
    "        X_train_arr.append(train[features_used])\n",
    "        X_test_arr.append(test[features_used])\n",
    "        Y_train_arr.append(train[\"cod\"])\n",
    "        Y_test_arr.append(test[\"cod\"])\n",
    "        info_train_arr.append(train[[\"datetime\", \"Location\"]])\n",
    "        info_test_arr.append((test[[\"datetime\", \"Location\"]]))\n",
    "    return X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, info_train_arr, info_test_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3e8742",
   "metadata": {},
   "source": [
    "Make the model and finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1483afd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetuning XGBoost\n",
    "def objective_xgboost(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": 200,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log = True),\n",
    "        \"verbosity\": 0,\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0, 1),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"enable_categorical\": True,\n",
    "        \"random_state\": 101\n",
    "    }\n",
    "\n",
    "    xgbr = XGBRegressor(**params)\n",
    "    cv_rmse = 0\n",
    "\n",
    "    for i in range(5):\n",
    "        X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "        Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "        xgbr.fit(X_train, Y_train)\n",
    "        Y_pred = xgbr.predict(X_test)\n",
    "        cv_rmse += root_mean_squared_error(Y_test, Y_pred)\n",
    "    \n",
    "    return cv_rmse / 5\n",
    "\n",
    "def objective_lightgbm(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": 200,\n",
    "        \"verbosity\": -1,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 2**10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.05, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "        \"random_state\": 101\n",
    "    }\n",
    "\n",
    "    lgbr = LGBMRegressor(**params)\n",
    "    cv_rmse = 0\n",
    "\n",
    "    for i in range(5):\n",
    "        X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "        Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "        lgbr.fit(X_train, Y_train)\n",
    "        Y_pred = lgbr.predict(X_test)\n",
    "        cv_rmse += root_mean_squared_error(Y_test, Y_pred)\n",
    "    \n",
    "    return cv_rmse / 5\n",
    "\n",
    "def objective_catboost(trial):\n",
    "    params = {\n",
    "        \"iterations\": 200,\n",
    "        \"verbose\": False,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 2, 600),\n",
    "        \"random_seed\": 37\n",
    "    }\n",
    "\n",
    "    cbr = CatBoostRegressor(**params)\n",
    "    cv_rmse = 0\n",
    "\n",
    "    for i in range(5):\n",
    "        X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "        Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "        cbr.fit(X_train, Y_train)\n",
    "        Y_pred = cbr.predict(X_test)\n",
    "        cv_rmse += root_mean_squared_error(Y_test, Y_pred)\n",
    "    \n",
    "    return cv_rmse / 5\n",
    "\n",
    "def objective_xgboost_with_val(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": 1000,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log = True),\n",
    "        \"verbosity\": 0,\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0, 1),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"enable_categorical\": True,\n",
    "        \"random_state\": 101,\n",
    "        \"early_stopping_rounds\": 20\n",
    "    }\n",
    "\n",
    "    xgbr = XGBRegressor(**params)\n",
    "    cv_rmse = 0\n",
    "\n",
    "    for i in range(5):\n",
    "        X_train, X_val, X_test = X_train_arr[i], X_val_arr[i], X_test_arr[i]\n",
    "        Y_train, Y_val, Y_test = Y_train_arr[i], Y_val_arr[i], Y_test_arr[i]\n",
    "        xgbr.fit(\n",
    "            X_train, \n",
    "            Y_train,\n",
    "            eval_set=[(X_val, Y_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "        Y_pred = xgbr.predict(X_test)\n",
    "        cv_rmse += root_mean_squared_error(Y_test, Y_pred)\n",
    "    \n",
    "    return cv_rmse / 5\n",
    "\n",
    "def objective_catboost_with_val(trial):\n",
    "    params = {\n",
    "        \"iterations\": 1000,\n",
    "        \"verbose\": False,\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 1, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.05, 1.0),\n",
    "        \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.05, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 2, 600),\n",
    "        \"random_seed\": 37,\n",
    "        \"early_stopping_rounds\": 20\n",
    "    }\n",
    "\n",
    "    cbr = CatBoostRegressor(**params)\n",
    "    cv_rmse = 0\n",
    "\n",
    "    for i in range(5):\n",
    "        X_train, X_val, X_test = X_train_arr[i], X_val_arr[i], X_test_arr[i]\n",
    "        Y_train, Y_val, Y_test = Y_train_arr[i], Y_val_arr[i], Y_test_arr[i]\n",
    "        cbr.fit(\n",
    "            X_train, \n",
    "            Y_train,\n",
    "            eval_set=[(X_val, Y_val)],\n",
    "            verbose=False\n",
    "        )\n",
    "        Y_pred = cbr.predict(X_test)\n",
    "        cv_rmse += root_mean_squared_error(Y_test, Y_pred)\n",
    "    \n",
    "    return cv_rmse / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a930e7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_xgboost(study_name, storage_name, objective_function=objective_xgboost, n_trials = 50):\n",
    "    print(\"Conduct hyperparam opt for XGBoost\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction ='minimize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = RandomSampler(seed = 101),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=2)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best RMSE:', study.best_value)\n",
    "    return study.best_params\n",
    "\n",
    "def optimize_lightgbm(study_name, storage_name, objective_function=objective_lightgbm, n_trials = 50):\n",
    "    print(\"Conduct hyperparam opt for LightGBM\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction='minimize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = RandomSampler(seed = 101),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=2)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best MSE:', study.best_value)\n",
    "    return study.best_params\n",
    "\n",
    "def optimize_catboost(study_name, storage_name, objective_function=objective_catboost, n_trials = 50):\n",
    "    print(\"Conduct hyperparam opt for CatBoost\")\n",
    "    study = optuna.create_study(\n",
    "        study_name = study_name,\n",
    "        direction='minimize',\n",
    "        storage = f\"sqlite:///{storage_name}.db\",\n",
    "        sampler = RandomSampler(seed = 101),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=2)\n",
    "    print('Best hyperparameters:', study.best_params)\n",
    "    print('Best RMSLE:', study.best_value)\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddad1809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 1 month for test and previous montsh for predict\n",
    "# Take 1: only use features appear in all data\n",
    "features_used = [f\"cod_prev_{i}\" for i in range(4, 13)] + \\\n",
    "                [f\"temp_prev_{i}\" for i in range(4, 13)] + \\\n",
    "                [f\"ph_prev_{i}\" for i in range(4, 13)] + \\\n",
    "                [f\"tss_prev_{i}\" for i in range(4, 13)] + \\\n",
    "                [\"sin_hour\", \"sin_day\", \"sin_month\"] # try to use sine version instead of numerical due to the cyclical nature of date\n",
    "#                [f\"nh4_prev_{i}\" for i in range(4, 9)]\n",
    "# features_used = [c for c in df.columns if \"prev\" in c and df[c].dtypes in [\"int64\", \"float64\"]]\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv_split(df, features_used)\n",
    "\n",
    "# baseline: using last k hours to predict\n",
    "baseline_score = 0\n",
    "for i in range(5):\n",
    "    baseline_score += np.sqrt(np.mean((Y_test_arr[i] - X_test_arr[i][f\"cod_prev_4\"])**2))\n",
    "baseline_score /= 5\n",
    "print(baseline_score)\n",
    "\n",
    "for loc in df[\"Location\"].unique():\n",
    "    print(loc)\n",
    "    temp_df = deepcopy(df[df[\"Location\"] == loc])\n",
    "    X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv_split(temp_df, features_used)\n",
    "    for i in range(5):\n",
    "        print(i, np.sqrt(np.mean((Y_test_arr[i] - X_test_arr[i][f\"cod_prev_4\"])**2)))\n",
    "\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv_split(df, features_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14d56f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgboost = optimize_xgboost(\n",
    "    f\"xgboost_study_{str(date.today())}\", \n",
    "    f\"xgboost_study_{str(date.today())}\"\n",
    ")\n",
    "# best is 2.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f33d150",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lightgbm = optimize_lightgbm(\n",
    "    f\"lightgbm_study_{str(date.today())}\", \n",
    "    f\"lightgbm_study_{str(date.today())}\"\n",
    ") \n",
    "# best is 2.96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5c13ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_catboost = optimize_catboost(\n",
    "    f\"catboost_study_{str(date.today())}\", \n",
    "    f\"catboost_study_{str(date.today())}\"\n",
    ")\n",
    "# best is this one, about 2.81 RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ba73d7",
   "metadata": {},
   "source": [
    "Testing on best configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113b0cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 200,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": 101\n",
    "}\n",
    "for p in best_params_xgboost:\n",
    "    params[p] = best_params_xgboost[p]\n",
    "\n",
    "feature_importances = {}\n",
    "\n",
    "xgbr = XGBRegressor(**params)\n",
    "for i in range(5):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    xgbr.fit(X_train, Y_train)\n",
    "    features = xgbr.feature_names_in_.tolist()\n",
    "    features_i = xgbr.feature_importances_.tolist()\n",
    "    for inx, feat in enumerate(features):\n",
    "        feature_importances[feat] = feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "feature_importances\n",
    "# Seems like only COD features are important (can try to only use 4-8 hours if 4-13 hours does not work well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6582790",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 200,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": 101,\n",
    "}\n",
    "for p in best_params_lightgbm:\n",
    "    params[p] = best_params_lightgbm[p]\n",
    "\n",
    "feature_importances = {}\n",
    "\n",
    "lgbr = LGBMRegressor(**params)\n",
    "for i in range(5):\n",
    "    X_train = X_train_arr[i]\n",
    "    Y_train = Y_train_arr[i]\n",
    "    lgbr.fit(X_train, Y_train)\n",
    "    features = lgbr.feature_names_in_.tolist()\n",
    "    features_i = lgbr.feature_importances_.tolist()\n",
    "    for inx, feat in enumerate(features):\n",
    "        feature_importances[feat] = feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "feature_importances\n",
    "# seems to pick up time features not as good as past 4 hours features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6afe2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"iterations\": 200,\n",
    "    \"verbose\": False,\n",
    "    \"random_seed\": 37\n",
    "}\n",
    "for p in best_params_catboost:\n",
    "    params[p] = best_params_catboost[p]\n",
    "\n",
    "feature_importances = {}\n",
    "\n",
    "cbr = CatBoostRegressor(**params)\n",
    "cv_rmse = 0\n",
    "\n",
    "for i in range(5):\n",
    "    X_train = X_train_arr[i]\n",
    "    Y_train = Y_train_arr[i]\n",
    "    cbr.fit(X_train, Y_train)\n",
    "    features = cbr.feature_names_\n",
    "    features_i = cbr.feature_importances_.tolist()\n",
    "    for inx, feat in enumerate(features):\n",
    "        feature_importances[feat] = feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "feature_importances\n",
    "# can pick up a combination of both past cod and tss, not good at picking up ph, temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054ba97e",
   "metadata": {},
   "source": [
    "Try to train with only previous CODs insteads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c72a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_used = [f\"cod_prev_{i}\" for i in range(4, 13)] \n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv_split(df, features_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158cf409",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgboost_only_cod = optimize_xgboost(\n",
    "    \"xgboost_study_only_cod_2025-05-03\", #f\"xgboost_study_only_cod_{str(date.today())}\",\n",
    "    \"xgboost_study_only_cod_2025-05-03\" #f\"xgboost_study_only_cod_{str(date.today())}\",\n",
    ")\n",
    "# seems to not improve?, might be because using all 4-12 hours cod before does not work => use 4-8 hours before\n",
    "# still 2.87 in the best version that only use cod, worse than best version that use all features\n",
    "# seems to better by including other features than just time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8c6635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to train with less values of cod\n",
    "features_used = [f\"cod_prev_{i}\" for i in range(4, 9)] \n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv_split(df, features_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ecf36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgboost_only_cod_truncated = optimize_xgboost(\n",
    "    f\"xgboost_study_only_cod_truncated_{str(date.today())}\",\n",
    "    f\"xgboost_study_only_cod_truncated_{str(date.today())}\",\n",
    ") #worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8559c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_used = [f\"cod_prev_{i}\" for i in range(4, 13)] \n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv_split(df, features_used)\n",
    "\n",
    "params = {\n",
    "    \"n_estimators\": 200,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": 101\n",
    "}\n",
    "for p in best_params_xgboost_only_cod:\n",
    "    params[p] = best_params_xgboost_only_cod[p]\n",
    "\n",
    "feature_importances = {}\n",
    "\n",
    "xgbr = XGBRegressor(**params)\n",
    "for i in range(5):\n",
    "    X_train = X_train_arr[i]\n",
    "    Y_train = Y_train_arr[i]\n",
    "    xgbr.fit(X_train, Y_train)\n",
    "    features = xgbr.feature_names_in_.tolist()\n",
    "    features_i = xgbr.feature_importances_.tolist()\n",
    "    for inx, feat in enumerate(features):\n",
    "        feature_importances[feat] = feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb81872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interesting relationship between importance of cod_prev_4, 5, 12 vs cod => try to only use them?\n",
    "features_used = [f\"cod_prev_{i}\" for i in [4, 5, 6, 12]] \n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv_split(df, features_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2af3c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgboost_only_cod_truncated_2 = optimize_xgboost(\n",
    "    f\"xgboost_study_only_cod_truncated_2_{str(date.today())}\",\n",
    "    f\"xgboost_study_only_cod_truncated_2_{str(date.today())}\",\n",
    ") # better than truncated, not as good as truncated 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aeff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#     \"iterations\": 200,\n",
    "#     \"verbose\": False,\n",
    "#     \"random_seed\": 37\n",
    "# }\n",
    "# for p in best_params_catboost_only_cod:\n",
    "#     params[p] = best_params_catboost_only_cod[p]\n",
    "\n",
    "# feature_importances = {}\n",
    "\n",
    "# cbr = CatBoostRegressor(**params)\n",
    "# cv_rmse = 0\n",
    "\n",
    "# for i in range(5):\n",
    "#     X_train = X_train_arr[i]\n",
    "#     Y_train = Y_train_arr[i]\n",
    "#     cbr.fit(X_train, Y_train)\n",
    "#     features = cbr.feature_names_\n",
    "#     features_i = cbr.feature_importances_.tolist()\n",
    "#     for inx, feat in enumerate(features):\n",
    "#         feature_importances[feat] = feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "# feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad73be5",
   "metadata": {},
   "source": [
    "Try to using only last 4 hours cod and some non-cod features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5932a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 1 month for test and previous montsh for predict\n",
    "# Take 1: only use features appear in all data\n",
    "features_used = [\"cod_prev_4\", \"temp_prev_4\", \"ph_prev_4\", \"tss_prev_4\", \"hour\", \"day\", \"month\"]\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv_split(df, features_used)\n",
    "# not really good, try to use an extended version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75606df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lightgbm_only_4h = optimize_lightgbm(\n",
    "    f\"lightgbm_study_only_4h_{str(date.today())}\",\n",
    "    f\"lightgbm_study_only_4h_{str(date.today())}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a76b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 200,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": 101\n",
    "}\n",
    "for p in best_params_lightgbm_only_4h:\n",
    "    params[p] = best_params_lightgbm_only_4h[p]\n",
    "\n",
    "feature_importances = {}\n",
    "\n",
    "lgbr = LGBMRegressor(**params)\n",
    "for i in range(5):\n",
    "    X_train = X_train_arr[i]\n",
    "    Y_train = Y_train_arr[i]\n",
    "    lgbr.fit(X_train, Y_train)\n",
    "    features = lgbr.feature_names_in_.tolist()\n",
    "    features_i = lgbr.feature_importances_.tolist()\n",
    "    for inx, feat in enumerate(features):\n",
    "        feature_importances[feat] = feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ab12d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 1 month for test and previous montsh for predict\n",
    "# Take 1: only use features appear in all data\n",
    "features_used = [\"cod_prev_4\", \"ph_prev_4\", \"tss_prev_4\", \"month\"]\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv_split(df, features_used)\n",
    "# not really good, try to use an extended version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e343dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_lightgbm_only_4h_truncated = optimize_lightgbm(\n",
    "    f\"lightgbm_study_only_4h_truncated_{str(date.today())}\",\n",
    "    f\"lightgbm_study_only_4h_truncated_{str(date.today())}\"\n",
    ")\n",
    "# worse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e381ecee",
   "metadata": {},
   "source": [
    "Try to look at special combination based on catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a1940",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_used = [f\"cod_prev_{i}\" for i in range(4, 13)] + \\\n",
    "                [\"hour\", \"day\", \"month\"] + \\\n",
    "                [\"tss_prev_4\", \"tss_prev_5\"]\n",
    "\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv_split(df, features_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1949134",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_catboost_best_comb = optimize_catboost(\n",
    "    \"catboost_study_best_comb_2025-05-03\", #f\"catboost_study_best_comb_{str(date.today())}\",\n",
    "    \"catboost_study_best_comb_2025-05-03\" #f\"catboost_study_best_comb_{str(date.today())}\"\n",
    ")\n",
    "#2.77, current best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a88e403",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"iterations\": 200,\n",
    "    \"verbose\": False,\n",
    "    \"random_seed\": 37\n",
    "}\n",
    "for p in best_params_catboost_best_comb:\n",
    "    params[p] = best_params_catboost_best_comb[p]\n",
    "\n",
    "feature_importances = {}\n",
    "\n",
    "cbr = CatBoostRegressor(**params)\n",
    "cv_rmse = 0\n",
    "\n",
    "for i in range(5):\n",
    "    X_train = X_train_arr[i]\n",
    "    Y_train = Y_train_arr[i]\n",
    "    cbr.fit(X_train, Y_train)\n",
    "    features = cbr.feature_names_\n",
    "    features_i = cbr.feature_importances_.tolist()\n",
    "    for inx, feat in enumerate(features):\n",
    "        feature_importances[feat] = feature_importances.get(feat, 0) + features_i[inx]\n",
    "\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1302395",
   "metadata": {},
   "source": [
    "Try to look at specific region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9f2898",
   "metadata": {},
   "outputs": [],
   "source": [
    "baymau_df = df[df[\"Location\"] == \"BAY MAU.csv\"].reset_index().drop(\"index\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cf7ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_used = [f\"cod_prev_{i}\" for i in range(4, 9)]\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv_split(baymau_df, features_used)\n",
    "\n",
    "# baseline\n",
    "baseline_score = 0\n",
    "for i in range(5):\n",
    "    baseline_score += np.sqrt(np.mean((Y_test_arr[i] - X_test_arr[i][f\"cod_prev_4\"])**2))\n",
    "baseline_score / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98043ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgboost_only_cod_baymau = optimize_xgboost(\n",
    "    f\"xgboost_study_only_cod_baymau_{str(date.today())}\",\n",
    "    f\"xgboost_study_only_cod_baymau_{str(date.today())}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76617e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "btlvt_df = df[df[\"Location\"] == \"BTLVT.csv\"].reset_index().drop(\"index\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4d4171",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_used = [f\"cod_prev_{i}\" for i in range(4, 9)]\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv_split(btlvt_df, features_used)\n",
    "\n",
    "# baseline\n",
    "baseline_score = 0\n",
    "for i in range(5):\n",
    "    baseline_score += np.sqrt(np.mean((Y_test_arr[i] - X_test_arr[i][f\"cod_prev_4\"])**2))\n",
    "baseline_score / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550a82a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgboost_only_cod_btlvt = optimize_xgboost(\n",
    "    f\"xgboost_study_only_cod_btlvt_{str(date.today())}\",\n",
    "    f\"xgboost_study_only_cod_btlvt_{str(date.today())}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844af8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "caunga_df = df[df[\"Location\"] == \"CAU NGA.csv\"].reset_index().drop(\"index\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b168fb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_used = [f\"cod_prev_{i}\" for i in range(4, 9)]\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv_split(caunga_df, features_used)\n",
    "\n",
    "# baseline\n",
    "baseline_score = 0\n",
    "for i in range(5):\n",
    "    baseline_score += np.sqrt(np.mean((Y_test_arr[i] - X_test_arr[i][f\"cod_prev_4\"])**2))\n",
    "baseline_score / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a3f779",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgboost_only_cod_caunga = optimize_xgboost(\n",
    "    f\"xgboost_study_only_cod_caunga_{str(date.today())}\",\n",
    "    f\"xgboost_study_only_cod_caunga_{str(date.today())}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ebb33e",
   "metadata": {},
   "source": [
    "Analyze error from model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db28364c",
   "metadata": {},
   "source": [
    "Best model that only use COD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef2eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_used = [f\"cod_prev_{i}\" for i in range(4, 13)] + \\\n",
    "                [f\"temp_prev_{i}\" for i in range(4, 13)] + \\\n",
    "                [f\"ph_prev_{i}\" for i in range(4, 13)] + \\\n",
    "                [f\"tss_prev_{i}\" for i in range(4, 13)] + \\\n",
    "                [\"hour\", \"day\", \"month\"]\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, info_train_arr, info_test_arr = create_cv_split_with_info(df, features_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68384541",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"iterations\": 200,\n",
    "    \"verbose\": False,\n",
    "    \"random_seed\": 37\n",
    "}\n",
    "for p in best_params_catboost_only_cod:\n",
    "    params[p] = best_params_catboost_only_cod[p]\n",
    "\n",
    "cbr = CatBoostRegressor(**params)\n",
    "\n",
    "X_train, X_test = X_train_arr[0], X_test_arr[0]\n",
    "Y_train, Y_test = Y_train_arr[0], Y_test_arr[0]\n",
    "info_train, info_test = info_train_arr[0], info_test_arr[0]\n",
    "cbr.fit(X_train, Y_train)\n",
    "Y_pred = cbr.predict(X_test)\n",
    "temp = pd.DataFrame({\n",
    "    \"Location\": info_test[\"Location\"],\n",
    "    \"datetime\": info_test[\"datetime\"],\n",
    "    \"true_cod\": Y_test,\n",
    "    \"pred_cod\": Y_pred\n",
    "})\n",
    "\n",
    "print(root_mean_squared_error(Y_test, Y_pred))\n",
    "fig, ax = plt.subplots(nrows = 3, ncols = 2, figsize = (10, 15))\n",
    "for inx, loc in enumerate(df[\"Location\"].unique()):\n",
    "    temp_df = temp[temp[\"Location\"] == loc]\n",
    "    print(loc, root_mean_squared_error(temp_df[\"true_cod\"], temp_df[\"pred_cod\"]))\n",
    "    x, y = inx // 2, inx % 2\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"true_cod\"], color = \"green\")\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"pred_cod\"], color = \"red\")\n",
    "    ax[x][y].set_title(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1307e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"iterations\": 200,\n",
    "    \"verbose\": False,\n",
    "    \"random_seed\": 37\n",
    "}\n",
    "for p in best_params_catboost_only_cod:\n",
    "    params[p] = best_params_catboost_only_cod[p]\n",
    "\n",
    "cbr = CatBoostRegressor(**params)\n",
    "\n",
    "X_train, X_test = X_train_arr[1], X_test_arr[1]\n",
    "Y_train, Y_test = Y_train_arr[1], Y_test_arr[1]\n",
    "info_train, info_test = info_train_arr[1], info_test_arr[1]\n",
    "cbr.fit(X_train, Y_train)\n",
    "Y_pred = cbr.predict(X_test)\n",
    "temp = pd.DataFrame({\n",
    "    \"Location\": info_test[\"Location\"],\n",
    "    \"datetime\": info_test[\"datetime\"],\n",
    "    \"true_cod\": Y_test,\n",
    "    \"pred_cod\": Y_pred\n",
    "})\n",
    "\n",
    "print(root_mean_squared_error(Y_test, Y_pred))\n",
    "fig, ax = plt.subplots(nrows = 3, ncols = 2, figsize = (10, 15))\n",
    "for inx, loc in enumerate(df[\"Location\"].unique()):\n",
    "    temp_df = temp[temp[\"Location\"] == loc]\n",
    "    print(loc, root_mean_squared_error(temp_df[\"true_cod\"], temp_df[\"pred_cod\"]))\n",
    "    x, y = inx // 2, inx % 2\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"true_cod\"], color = \"green\")\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"pred_cod\"], color = \"red\")\n",
    "    ax[x][y].set_title(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83620d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"iterations\": 200,\n",
    "    \"verbose\": False,\n",
    "    \"random_seed\": 37\n",
    "}\n",
    "for p in best_params_catboost_only_cod:\n",
    "    params[p] = best_params_catboost_only_cod[p]\n",
    "\n",
    "cbr = CatBoostRegressor(**params)\n",
    "\n",
    "X_train, X_test = X_train_arr[2], X_test_arr[2]\n",
    "Y_train, Y_test = Y_train_arr[2], Y_test_arr[2]\n",
    "info_train, info_test = info_train_arr[2], info_test_arr[2]\n",
    "cbr.fit(X_train, Y_train)\n",
    "Y_pred = cbr.predict(X_test)\n",
    "temp = pd.DataFrame({\n",
    "    \"Location\": info_test[\"Location\"],\n",
    "    \"datetime\": info_test[\"datetime\"],\n",
    "    \"true_cod\": Y_test,\n",
    "    \"pred_cod\": Y_pred\n",
    "})\n",
    "\n",
    "print(root_mean_squared_error(Y_test, Y_pred))\n",
    "fig, ax = plt.subplots(nrows = 3, ncols = 2, figsize = (10, 15))\n",
    "for inx, loc in enumerate(df[\"Location\"].unique()):\n",
    "    temp_df = temp[temp[\"Location\"] == loc]\n",
    "    print(loc, root_mean_squared_error(temp_df[\"true_cod\"], temp_df[\"pred_cod\"]))\n",
    "    x, y = inx // 2, inx % 2\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"true_cod\"], color = \"green\")\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"pred_cod\"], color = \"red\")\n",
    "    ax[x][y].set_title(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f3b1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"iterations\": 200,\n",
    "    \"verbose\": False,\n",
    "    \"random_seed\": 37\n",
    "}\n",
    "for p in best_params_catboost_only_cod:\n",
    "    params[p] = best_params_catboost_only_cod[p]\n",
    "\n",
    "cbr = CatBoostRegressor(**params)\n",
    "\n",
    "X_train, X_test = X_train_arr[3], X_test_arr[3]\n",
    "Y_train, Y_test = Y_train_arr[3], Y_test_arr[3]\n",
    "info_train, info_test = info_train_arr[3], info_test_arr[3]\n",
    "cbr.fit(X_train, Y_train)\n",
    "Y_pred = cbr.predict(X_test)\n",
    "temp = pd.DataFrame({\n",
    "    \"Location\": info_test[\"Location\"],\n",
    "    \"datetime\": info_test[\"datetime\"],\n",
    "    \"true_cod\": Y_test,\n",
    "    \"pred_cod\": Y_pred\n",
    "})\n",
    "\n",
    "print(root_mean_squared_error(Y_test, Y_pred))\n",
    "fig, ax = plt.subplots(nrows = 3, ncols = 2, figsize = (10, 15))\n",
    "for inx, loc in enumerate(df[\"Location\"].unique()):\n",
    "    temp_df = temp[temp[\"Location\"] == loc]\n",
    "    print(loc, root_mean_squared_error(temp_df[\"true_cod\"], temp_df[\"pred_cod\"]))\n",
    "    x, y = inx // 2, inx % 2\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"true_cod\"], color = \"green\")\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"pred_cod\"], color = \"red\")\n",
    "    ax[x][y].set_title(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0181d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"iterations\": 200,\n",
    "    \"verbose\": False,\n",
    "    \"random_seed\": 37\n",
    "}\n",
    "for p in best_params_catboost_only_cod:\n",
    "    params[p] = best_params_catboost_only_cod[p]\n",
    "\n",
    "cbr = CatBoostRegressor(**params)\n",
    "\n",
    "X_train, X_test = X_train_arr[4], X_test_arr[4]\n",
    "Y_train, Y_test = Y_train_arr[4], Y_test_arr[4]\n",
    "info_train, info_test = info_train_arr[4], info_test_arr[4]\n",
    "cbr.fit(X_train, Y_train)\n",
    "Y_pred = cbr.predict(X_test)\n",
    "temp = pd.DataFrame({\n",
    "    \"Location\": info_test[\"Location\"],\n",
    "    \"datetime\": info_test[\"datetime\"],\n",
    "    \"true_cod\": Y_test,\n",
    "    \"pred_cod\": Y_pred\n",
    "})\n",
    "\n",
    "print(root_mean_squared_error(Y_test, Y_pred))\n",
    "fig, ax = plt.subplots(nrows = 3, ncols = 2, figsize = (10, 15))\n",
    "for inx, loc in enumerate(df[\"Location\"].unique()):\n",
    "    temp_df = temp[temp[\"Location\"] == loc]\n",
    "    print(loc, root_mean_squared_error(temp_df[\"true_cod\"], temp_df[\"pred_cod\"]))\n",
    "    x, y = inx // 2, inx % 2\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"true_cod\"], color = \"green\")\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"pred_cod\"], color = \"red\")\n",
    "    ax[x][y].set_title(loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a9884c",
   "metadata": {},
   "source": [
    "Best model that only use last 4 hours features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589df816",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_used = [\"cod_prev_4\", \"ph_prev_4\", \"tss_prev_4\", \"month\"]\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, info_train_arr, info_test_arr = create_cv_split_with_info(df, features_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df66da93",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"iterations\": 100,\n",
    "    \"verbose\": False,\n",
    "    \"random_seed\": 37\n",
    "}\n",
    "for p in best_params_catboost_only_4h:\n",
    "    params[p] = best_params_catboost_only_4h[p]\n",
    "\n",
    "cbr = CatBoostRegressor(**params)\n",
    "\n",
    "X_train, X_test = X_train_arr[0], X_test_arr[0]\n",
    "Y_train, Y_test = Y_train_arr[0], Y_test_arr[0]\n",
    "info_train, info_test = info_train_arr[0], info_test_arr[0]\n",
    "cbr.fit(X_train, Y_train)\n",
    "Y_pred = cbr.predict(X_test)\n",
    "temp = pd.DataFrame({\n",
    "    \"Location\": info_test[\"Location\"],\n",
    "    \"datetime\": info_test[\"datetime\"],\n",
    "    \"true_cod\": Y_test,\n",
    "    \"pred_cod\": Y_pred\n",
    "})\n",
    "\n",
    "print(root_mean_squared_error(Y_test, Y_pred))\n",
    "fig, ax = plt.subplots(nrows = 3, ncols = 2, figsize = (10, 15))\n",
    "for inx, loc in enumerate(df[\"Location\"].unique()):\n",
    "    temp_df = temp[temp[\"Location\"] == loc]\n",
    "    x, y = inx // 2, inx % 2\n",
    "    print(loc, root_mean_squared_error(temp_df[\"true_cod\"], temp_df[\"pred_cod\"]))\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"true_cod\"], color = \"green\")\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"pred_cod\"], color = \"red\")\n",
    "    ax[x][y].set_title(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda378e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"iterations\": 100,\n",
    "    \"verbose\": False,\n",
    "    \"random_seed\": 37\n",
    "}\n",
    "for p in best_params_catboost_only_4h:\n",
    "    params[p] = best_params_catboost_only_4h[p]\n",
    "\n",
    "cbr = CatBoostRegressor(**params)\n",
    "\n",
    "X_train, X_test = X_train_arr[1], X_test_arr[1]\n",
    "Y_train, Y_test = Y_train_arr[1], Y_test_arr[1]\n",
    "info_train, info_test = info_train_arr[1], info_test_arr[1]\n",
    "cbr.fit(X_train, Y_train)\n",
    "Y_pred = cbr.predict(X_test)\n",
    "temp = pd.DataFrame({\n",
    "    \"Location\": info_test[\"Location\"],\n",
    "    \"datetime\": info_test[\"datetime\"],\n",
    "    \"true_cod\": Y_test,\n",
    "    \"pred_cod\": Y_pred\n",
    "})\n",
    "\n",
    "print(root_mean_squared_error(Y_test, Y_pred))\n",
    "fig, ax = plt.subplots(nrows = 3, ncols = 2, figsize = (10, 15))\n",
    "for inx, loc in enumerate(df[\"Location\"].unique()):\n",
    "    temp_df = temp[temp[\"Location\"] == loc]\n",
    "    x, y = inx // 2, inx % 2\n",
    "    print(loc, root_mean_squared_error(temp_df[\"true_cod\"], temp_df[\"pred_cod\"]))\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"true_cod\"], color = \"green\")\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"pred_cod\"], color = \"red\")\n",
    "    ax[x][y].set_title(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67a9326",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"iterations\": 100,\n",
    "    \"verbose\": False,\n",
    "    \"random_seed\": 37\n",
    "}\n",
    "for p in best_params_catboost_only_4h:\n",
    "    params[p] = best_params_catboost_only_4h[p]\n",
    "\n",
    "cbr = CatBoostRegressor(**params)\n",
    "\n",
    "X_train, X_test = X_train_arr[2], X_test_arr[2]\n",
    "Y_train, Y_test = Y_train_arr[2], Y_test_arr[2]\n",
    "info_train, info_test = info_train_arr[2], info_test_arr[2]\n",
    "cbr.fit(X_train, Y_train)\n",
    "Y_pred = cbr.predict(X_test)\n",
    "temp = pd.DataFrame({\n",
    "    \"Location\": info_test[\"Location\"],\n",
    "    \"datetime\": info_test[\"datetime\"],\n",
    "    \"true_cod\": Y_test,\n",
    "    \"pred_cod\": Y_pred\n",
    "})\n",
    "\n",
    "print(root_mean_squared_error(Y_test, Y_pred))\n",
    "fig, ax = plt.subplots(nrows = 3, ncols = 2, figsize = (10, 15))\n",
    "for inx, loc in enumerate(df[\"Location\"].unique()):\n",
    "    temp_df = temp[temp[\"Location\"] == loc]\n",
    "    x, y = inx // 2, inx % 2\n",
    "    print(loc, root_mean_squared_error(temp_df[\"true_cod\"], temp_df[\"pred_cod\"]))\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"true_cod\"], color = \"green\")\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"pred_cod\"], color = \"red\")\n",
    "    ax[x][y].set_title(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31521b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"iterations\": 100,\n",
    "    \"verbose\": False,\n",
    "    \"random_seed\": 37\n",
    "}\n",
    "for p in best_params_catboost_only_4h:\n",
    "    params[p] = best_params_catboost_only_4h[p]\n",
    "\n",
    "cbr = CatBoostRegressor(**params)\n",
    "\n",
    "X_train, X_test = X_train_arr[3], X_test_arr[3]\n",
    "Y_train, Y_test = Y_train_arr[3], Y_test_arr[3]\n",
    "info_train, info_test = info_train_arr[3], info_test_arr[3]\n",
    "cbr.fit(X_train, Y_train)\n",
    "Y_pred = cbr.predict(X_test)\n",
    "temp = pd.DataFrame({\n",
    "    \"Location\": info_test[\"Location\"],\n",
    "    \"datetime\": info_test[\"datetime\"],\n",
    "    \"true_cod\": Y_test,\n",
    "    \"pred_cod\": Y_pred\n",
    "})\n",
    "\n",
    "print(root_mean_squared_error(Y_test, Y_pred))\n",
    "fig, ax = plt.subplots(nrows = 3, ncols = 2, figsize = (10, 15))\n",
    "for inx, loc in enumerate(df[\"Location\"].unique()):\n",
    "    temp_df = temp[temp[\"Location\"] == loc]\n",
    "    x, y = inx // 2, inx % 2\n",
    "    print(loc, root_mean_squared_error(temp_df[\"true_cod\"], temp_df[\"pred_cod\"]))\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"true_cod\"], color = \"green\")\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"pred_cod\"], color = \"red\")\n",
    "    ax[x][y].set_title(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044b6c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"iterations\": 100,\n",
    "    \"verbose\": False,\n",
    "    \"random_seed\": 37\n",
    "}\n",
    "for p in best_params_catboost_only_4h:\n",
    "    params[p] = best_params_catboost_only_4h[p]\n",
    "\n",
    "cbr = CatBoostRegressor(**params)\n",
    "\n",
    "X_train, X_test = X_train_arr[4], X_test_arr[4]\n",
    "Y_train, Y_test = Y_train_arr[4], Y_test_arr[4]\n",
    "info_train, info_test = info_train_arr[4], info_test_arr[4]\n",
    "cbr.fit(X_train, Y_train)\n",
    "Y_pred = cbr.predict(X_test)\n",
    "temp = pd.DataFrame({\n",
    "    \"Location\": info_test[\"Location\"],\n",
    "    \"datetime\": info_test[\"datetime\"],\n",
    "    \"true_cod\": Y_test,\n",
    "    \"pred_cod\": Y_pred\n",
    "})\n",
    "\n",
    "print(root_mean_squared_error(Y_test, Y_pred))\n",
    "fig, ax = plt.subplots(nrows = 3, ncols = 2, figsize = (10, 15))\n",
    "for inx, loc in enumerate(df[\"Location\"].unique()):\n",
    "    temp_df = temp[temp[\"Location\"] == loc]\n",
    "    x, y = inx // 2, inx % 2\n",
    "    print(loc, root_mean_squared_error(temp_df[\"true_cod\"], temp_df[\"pred_cod\"]))\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"true_cod\"], color = \"green\")\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"pred_cod\"], color = \"red\")\n",
    "    ax[x][y].set_title(loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a5f96b",
   "metadata": {},
   "source": [
    "Best model that use some combination of both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcb6521",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_used = [f\"cod_prev_{i}\" for i in range(4, 13)] + \\\n",
    "                [\"hour\", \"day\", \"month\"] + \\\n",
    "                [\"tss_prev_4\", \"tss_prev_5\"]\n",
    "\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr, info_train_arr, info_test_arr = create_cv_split_with_info(df, features_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b548224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"iterations\": 200,\n",
    "    \"verbose\": False,\n",
    "    \"random_seed\": 37\n",
    "}\n",
    "for p in best_params_catboost_special_comb:\n",
    "    params[p] = best_params_catboost_special_comb[p]\n",
    "\n",
    "cbr = CatBoostRegressor(**params)\n",
    "\n",
    "X_train, X_test = X_train_arr[0], X_test_arr[0]\n",
    "Y_train, Y_test = Y_train_arr[0], Y_test_arr[0]\n",
    "info_train, info_test = info_train_arr[0], info_test_arr[0]\n",
    "cbr.fit(X_train, Y_train)\n",
    "Y_pred = cbr.predict(X_test)\n",
    "temp = pd.DataFrame({\n",
    "    \"Location\": info_test[\"Location\"],\n",
    "    \"datetime\": info_test[\"datetime\"],\n",
    "    \"true_cod\": Y_test,\n",
    "    \"pred_cod\": Y_pred\n",
    "})\n",
    "\n",
    "print(root_mean_squared_error(Y_test, Y_pred))\n",
    "fig, ax = plt.subplots(nrows = 3, ncols = 2, figsize = (10, 15))\n",
    "for inx, loc in enumerate(df[\"Location\"].unique()):\n",
    "    temp_df = temp[temp[\"Location\"] == loc]\n",
    "    x, y = inx // 2, inx % 2\n",
    "    print(loc, root_mean_squared_error(temp_df[\"true_cod\"], temp_df[\"pred_cod\"]))\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"true_cod\"], color = \"green\")\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"pred_cod\"], color = \"red\")\n",
    "    ax[x][y].set_title(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef11680",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"iterations\": 200,\n",
    "    \"verbose\": False,\n",
    "    \"random_seed\": 37\n",
    "}\n",
    "for p in best_params_catboost_special_comb:\n",
    "    params[p] = best_params_catboost_special_comb[p]\n",
    "\n",
    "cbr = CatBoostRegressor(**params)\n",
    "\n",
    "X_train, X_test = X_train_arr[1], X_test_arr[1]\n",
    "Y_train, Y_test = Y_train_arr[1], Y_test_arr[1]\n",
    "info_train, info_test = info_train_arr[1], info_test_arr[1]\n",
    "cbr.fit(X_train, Y_train)\n",
    "Y_pred = cbr.predict(X_test)\n",
    "temp = pd.DataFrame({\n",
    "    \"Location\": info_test[\"Location\"],\n",
    "    \"datetime\": info_test[\"datetime\"],\n",
    "    \"true_cod\": Y_test,\n",
    "    \"pred_cod\": Y_pred\n",
    "})\n",
    "\n",
    "print(root_mean_squared_error(Y_test, Y_pred))\n",
    "fig, ax = plt.subplots(nrows = 3, ncols = 2, figsize = (10, 15))\n",
    "for inx, loc in enumerate(df[\"Location\"].unique()):\n",
    "    temp_df = temp[temp[\"Location\"] == loc]\n",
    "    x, y = inx // 2, inx % 2\n",
    "    print(loc, root_mean_squared_error(temp_df[\"true_cod\"], temp_df[\"pred_cod\"]))\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"true_cod\"], color = \"green\")\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"pred_cod\"], color = \"red\")\n",
    "    ax[x][y].set_title(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dec9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"iterations\": 200,\n",
    "    \"verbose\": False,\n",
    "    \"random_seed\": 37\n",
    "}\n",
    "for p in best_params_catboost_special_comb:\n",
    "    params[p] = best_params_catboost_special_comb[p]\n",
    "\n",
    "cbr = CatBoostRegressor(**params)\n",
    "\n",
    "X_train, X_test = X_train_arr[2], X_test_arr[2]\n",
    "Y_train, Y_test = Y_train_arr[2], Y_test_arr[2]\n",
    "info_train, info_test = info_train_arr[2], info_test_arr[2]\n",
    "cbr.fit(X_train, Y_train)\n",
    "Y_pred = cbr.predict(X_test)\n",
    "temp = pd.DataFrame({\n",
    "    \"Location\": info_test[\"Location\"],\n",
    "    \"datetime\": info_test[\"datetime\"],\n",
    "    \"true_cod\": Y_test,\n",
    "    \"pred_cod\": Y_pred\n",
    "})\n",
    "\n",
    "print(root_mean_squared_error(Y_test, Y_pred))\n",
    "fig, ax = plt.subplots(nrows = 3, ncols = 2, figsize = (10, 15))\n",
    "for inx, loc in enumerate(df[\"Location\"].unique()):\n",
    "    temp_df = temp[temp[\"Location\"] == loc]\n",
    "    x, y = inx // 2, inx % 2\n",
    "    print(loc, root_mean_squared_error(temp_df[\"true_cod\"], temp_df[\"pred_cod\"]))\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"true_cod\"], color = \"green\")\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"pred_cod\"], color = \"red\")\n",
    "    ax[x][y].set_title(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06725ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"iterations\": 200,\n",
    "    \"verbose\": False,\n",
    "    \"random_seed\": 37\n",
    "}\n",
    "for p in best_params_catboost_special_comb:\n",
    "    params[p] = best_params_catboost_special_comb[p]\n",
    "\n",
    "cbr = CatBoostRegressor(**params)\n",
    "\n",
    "X_train, X_test = X_train_arr[3], X_test_arr[3]\n",
    "Y_train, Y_test = Y_train_arr[3], Y_test_arr[3]\n",
    "info_train, info_test = info_train_arr[3], info_test_arr[3]\n",
    "cbr.fit(X_train, Y_train)\n",
    "Y_pred = cbr.predict(X_test)\n",
    "temp = pd.DataFrame({\n",
    "    \"Location\": info_test[\"Location\"],\n",
    "    \"datetime\": info_test[\"datetime\"],\n",
    "    \"true_cod\": Y_test,\n",
    "    \"pred_cod\": Y_pred\n",
    "})\n",
    "\n",
    "print(root_mean_squared_error(Y_test, Y_pred))\n",
    "fig, ax = plt.subplots(nrows = 3, ncols = 2, figsize = (10, 15))\n",
    "for inx, loc in enumerate(df[\"Location\"].unique()):\n",
    "    temp_df = temp[temp[\"Location\"] == loc]\n",
    "    x, y = inx // 2, inx % 2\n",
    "    print(loc, root_mean_squared_error(temp_df[\"true_cod\"], temp_df[\"pred_cod\"]))\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"true_cod\"], color = \"green\")\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"pred_cod\"], color = \"red\")\n",
    "    ax[x][y].set_title(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ed7fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"iterations\": 200,\n",
    "    \"verbose\": False,\n",
    "    \"random_seed\": 37\n",
    "}\n",
    "for p in best_params_catboost_special_comb:\n",
    "    params[p] = best_params_catboost_special_comb[p]\n",
    "\n",
    "cbr = CatBoostRegressor(**params)\n",
    "\n",
    "X_train, X_test = X_train_arr[4], X_test_arr[4]\n",
    "Y_train, Y_test = Y_train_arr[4], Y_test_arr[4]\n",
    "info_train, info_test = info_train_arr[4], info_test_arr[4]\n",
    "cbr.fit(X_train, Y_train)\n",
    "Y_pred = cbr.predict(X_test)\n",
    "temp = pd.DataFrame({\n",
    "    \"Location\": info_test[\"Location\"],\n",
    "    \"datetime\": info_test[\"datetime\"],\n",
    "    \"true_cod\": Y_test,\n",
    "    \"pred_cod\": Y_pred\n",
    "})\n",
    "\n",
    "print(root_mean_squared_error(Y_test, Y_pred))\n",
    "fig, ax = plt.subplots(nrows = 3, ncols = 2, figsize = (10, 15))\n",
    "for inx, loc in enumerate(df[\"Location\"].unique()):\n",
    "    temp_df = temp[temp[\"Location\"] == loc]\n",
    "    x, y = inx // 2, inx % 2\n",
    "    print(loc, root_mean_squared_error(temp_df[\"true_cod\"], temp_df[\"pred_cod\"]))\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"true_cod\"], color = \"green\")\n",
    "    ax[x][y].scatter(temp_df[\"datetime\"], temp_df[\"pred_cod\"], color = \"red\")\n",
    "    ax[x][y].set_title(loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df8d5c0",
   "metadata": {},
   "source": [
    "Try to increase number of estimator + adding validation based on good set of features for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f2f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_used = [f\"cod_prev_{i}\" for i in range(4, 13)] + \\\n",
    "                [f\"temp_prev_{i}\" for i in range(4, 13)] + \\\n",
    "                [f\"ph_prev_{i}\" for i in range(4, 13)] + \\\n",
    "                [f\"tss_prev_{i}\" for i in range(4, 13)] + \\\n",
    "                [\"hour\", \"day\", \"month\"]\n",
    "X_train_arr, X_val_arr, X_test_arr, Y_train_arr, Y_val_arr, Y_test_arr = create_cv_split_with_val(df, features_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d9a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgboost_only_cod_with_val = optimize_xgboost(\n",
    "    f\"xgboost_study_only_cod_with_val_2025-05-04\",\n",
    "    f\"xgboost_study_only_cod_with_val_2025-05-04\",\n",
    "    objective_xgboost_with_val\n",
    ")\n",
    "# slightly worse than model with only 200 trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25bdd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_catboost_only_cod_with_val = optimize_catboost(\n",
    "    f\"catboost_study_only_cod_with_val_{str(date.today())}\",\n",
    "    f\"catboost_study_only_cod_with_val_{str(date.today())}\",\n",
    "    objective_catboost_with_val\n",
    ") # not better than original model with 200 trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8751971c",
   "metadata": {},
   "source": [
    "Try to combine best 3 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b60cf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_params_from_file(filename):\n",
    "    study = optuna.create_study(\n",
    "        study_name = filename,\n",
    "        direction='minimize',\n",
    "        storage = f\"sqlite:///{filename}.db\",\n",
    "        sampler = RandomSampler(seed = 101),\n",
    "        load_if_exists=True\n",
    "    )\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069fe6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframes for used\n",
    "features_used = [f\"cod_prev_{i}\" for i in range(4, 13)] + \\\n",
    "                [f\"temp_prev_{i}\" for i in range(4, 13)] + \\\n",
    "                [f\"ph_prev_{i}\" for i in range(4, 13)] + \\\n",
    "                [f\"tss_prev_{i}\" for i in range(4, 13)] + \\\n",
    "                [\"hour\", \"day\", \"month\"]\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv_split(df, features_used)\n",
    "\n",
    "# get best model params\n",
    "best_params_xgboost = get_best_params_from_file(\"xgboost_study_2025-05-02\")\n",
    "params = {\n",
    "    \"n_estimators\": 200,\n",
    "    \"verbosity\": 0,\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": 101\n",
    "}\n",
    "for p in best_params_xgboost:\n",
    "    params[p] = best_params_xgboost[p]\n",
    "\n",
    "# train list of models\n",
    "xgbr_arr = [XGBRegressor(**params)] * 5\n",
    "Y_pred_xgboost_arr = []\n",
    "for i in range(5):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    xgbr_arr[i].fit(X_train, Y_train)\n",
    "    Y_pred_xgboost_arr.append(xgbr_arr[i].predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774cd8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataframes for used\n",
    "features_used = [f\"cod_prev_{i}\" for i in range(4, 13)] + \\\n",
    "                [f\"temp_prev_{i}\" for i in range(4, 13)] + \\\n",
    "                [f\"ph_prev_{i}\" for i in range(4, 13)] + \\\n",
    "                [f\"tss_prev_{i}\" for i in range(4, 13)] + \\\n",
    "                [\"hour\", \"day\", \"month\"]\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv_split(df, features_used)\n",
    "\n",
    "# get best model params\n",
    "best_params_lightgbm = get_best_params_from_file(\"lightgbm_study_2025-05-02\")\n",
    "params = {\n",
    "    \"n_estimators\": 200,\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": 101\n",
    "}\n",
    "for p in best_params_lightgbm:\n",
    "    params[p] = best_params_lightgbm[p]\n",
    "\n",
    "# train list of models\n",
    "lgbr_arr = [LGBMRegressor(**params)] * 5\n",
    "Y_pred_lightgbm_arr = []\n",
    "for i in range(5):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    lgbr_arr[i].fit(X_train, Y_train)\n",
    "    Y_pred_lightgbm_arr.append(lgbr_arr[i].predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd20f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_used = [f\"cod_prev_{i}\" for i in range(4, 13)] + \\\n",
    "                [\"hour\", \"day\", \"month\"] + \\\n",
    "                [\"tss_prev_4\", \"tss_prev_5\"]\n",
    "X_train_arr, X_test_arr, Y_train_arr, Y_test_arr = create_cv_split(df, features_used)\n",
    "\n",
    "# get best model params\n",
    "best_params_catboost = get_best_params_from_file(\"catboost_study_best_comb_2025-05-03\")\n",
    "params = {\n",
    "    \"iterations\": 200,\n",
    "    \"verbose\": False,\n",
    "    \"random_seed\": 37\n",
    "}\n",
    "for p in best_params_catboost:\n",
    "    params[p] = best_params_catboost[p]\n",
    "\n",
    "# train list of models\n",
    "cbr_arr = [CatBoostRegressor(**params)] * 5\n",
    "Y_pred_catboost_arr = []\n",
    "for i in range(5):\n",
    "    X_train, X_test = X_train_arr[i], X_test_arr[i]\n",
    "    Y_train, Y_test = Y_train_arr[i], Y_test_arr[i]\n",
    "    cbr_arr[i].fit(X_train, Y_train)\n",
    "    Y_pred_catboost_arr.append(cbr_arr[i].predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2421cb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_rmse = 0\n",
    "cv_rmse_xgboost = 0\n",
    "cv_rmse_lightgbm = 0\n",
    "cv_rmse_catboost = 0\n",
    "for i in range(5):\n",
    "    print(f\"Error for xgboost at fold {i + 1}: {root_mean_squared_error(Y_test_arr[i], Y_pred_xgboost_arr[i])}\")\n",
    "    cv_rmse_xgboost += root_mean_squared_error(Y_test_arr[i], Y_pred_xgboost_arr[i])\n",
    "    print(f\"Error for lightgbm at fold {i + 1}: {root_mean_squared_error(Y_test_arr[i], Y_pred_lightgbm_arr[i])}\")\n",
    "    cv_rmse_lightgbm += root_mean_squared_error(Y_test_arr[i], Y_pred_lightgbm_arr[i])\n",
    "    print(f\"Error for catboost at fold {i + 1}: {root_mean_squared_error(Y_test_arr[i], Y_pred_catboost_arr[i])}\")\n",
    "    cv_rmse_catboost += root_mean_squared_error(Y_test_arr[i], Y_pred_catboost_arr[i])\n",
    "    Y_pred = 0.05 * Y_pred_xgboost_arr[i] + 0.05 * Y_pred_lightgbm_arr[i] + 0.9 * Y_pred_catboost_arr[i]\n",
    "    rmse = root_mean_squared_error(Y_test_arr[i], Y_pred)\n",
    "    print(f\"Error for combined model at fold {i + 1}: {rmse}\")\n",
    "    cv_rmse += rmse\n",
    "print(\"CV error of simple model:\")\n",
    "print(f\"xgboost: {cv_rmse_xgboost / 5}\")\n",
    "print(f\"lightgbm: {cv_rmse_lightgbm / 5}\")\n",
    "print(f\"catboost: {cv_rmse_catboost / 5}\")\n",
    "print(\"CV error of combined model\")\n",
    "print(cv_rmse / 5)\n",
    "# peak at 2.770 (better than 2.7716 of catbooost with good features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
